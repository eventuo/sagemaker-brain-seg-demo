{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain MRI Segmentation\n",
    "***Predict Brain Tissue Segmentation Masks from Brain MRI Scans***\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Exploratory Data Analyis & Pre-processing](#Exploratory-Data-Analysis-&-Pre-processing)\n",
    "1. [Train Models on Sagemaker](#Train-Models-on-SageMaker)\n",
    "1. [Inference Endpoints](#Inference-Endpoints)\n",
    "1. [Model Evaluation](#Model-Evaluation)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "## Background\n",
    "\n",
    "This notebook shows how to apply image segmentation algorithms to medical imaging use-cases in a simple, streamlined way using Amazon SageMaker. Specifically, we'll be using Apache MXNet to train a convolutional neural network for semantic segmentation on SageMaker using the \"Bring Your Own Script\" paradigm. Put simply, the goal of semantic segmentation is to make classifications on an image at the pixel-level, producing a classification \"mask.\" We will train two networks, U-Net and ENet. We'll show how to deploy these models to inference endpoints, both in the cloud on Amazon SageMaker and at the edge using AWS GreenGrass.\n",
    "\n",
    "### Use-case\n",
    "\n",
    "Medical imaging techniques allow medical professionals to see inside the human body, but more often than not the professional needs precise segmentation of the tissues within the image for analytical procedures and inferences. This is particular relevant in use-cases where volumetric and surface analysis are key to derive insights from the raw imaging, such as assessing the cardivascular health of a patient. Typically, this segmentation is done manually by medical professionals, and is very time consuming. Recently, convolutional neural networks have been shown to be highly performant at this task, and in this notebook we'll train two such networks to automatically segment brain tissue from MRI images.\n",
    "\n",
    "### CNN Architectures\n",
    "\n",
    "In this notebook, we apply two models to the task of brain tissue segmentation:\n",
    "* **U-Net**: Introduced in the paper [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597), this network was originally used for medical-imaging use-cases but has since proven to be reliable in generic segmentation domains. Due to it's architectural and conceptual simplicity, its often used as a baseline.\n",
    "* **ENet**: Introduced in the paper [ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation](https://arxiv.org/abs/1606.02147), ENet is designed to be low-latency and to operate in environments with low compute capacity (e.g. edge devices). Compared to existing architectures, ENet optimizes for processing time over accuracy.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this notebook, we'll be using Brain MRI data from the [Open Access Series of Imaging Studies (OASIS)](http://www.oasis-brains.org/). This project offers a wealth of neuroimaging datasets; we'll be looking at a small subset of cross-sectional brain MRIs.\n",
    "\n",
    "**Note:** You need to request access on the OASIS site to get the data. In this tutorial, I'll be using the <tt>disc1.tar.gz</tt> file from the [OASIS-1](http://www.oasis-brains.org/#data) data set.\n",
    "\n",
    "## Exploratory Data Analysis & Pre-processing\n",
    "\n",
    "In this section, we'll visualize the data and pre-process it for training a segmentation network. Once completed, we'll put the pre-processed data on S3 for SageMaker to use during model training.\n",
    "\n",
    "### Setup\n",
    "\n",
    "We'll start by importing the libraries necessary to perform the data visualization and pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import boto3\n",
    "import os\n",
    "from glob import glob\n",
    "import imageio\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "import urllib\n",
    "import tarfile\n",
    "import shutil\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & Extract\n",
    "Next, we're going to download the compressed data file locally and extract it to our data directory. I've put the <tt>disc1.tar.gx</tt> file in S3 and will download it from there.\n",
    "\n",
    "I've left the data directory up to you, because depending on your instance type you may or may not have the disk space to download and extract this data set. Some options:\n",
    "* Download data to the shared memory at <tt>/dev/shm</tt> if you have enough storage capacity there. Data saved here is not persistent, but we're only pre-processing and putting data on S3.\n",
    "* [Mount an Elastic File System to this instance.](https://aws.amazon.com/blogs/machine-learning/mount-an-efs-file-system-to-an-amazon-sagemaker-notebook-with-lifecycle-configurations/) This is useful if you want your data to persist in a file system accessible by your instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_bucket = '<YOUR-S3-BUCKET>'\n",
    "data_prefix = '<YOUR-S3-PREFIX>'\n",
    "data_dir = '<YOUR-DATA-DIR>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir_if_not_exist(d):\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download and extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_dir_if_not_exist(os.path.join(data_dir, 'brain_mri'))\n",
    "boto3.client('s3').download_file(\n",
    "    Bucket=data_bucket,\n",
    "    Key=data_prefix,\n",
    "    Filename=os.path.join(data_dir, \"brain_mri\", \"disc1.tar.gz\")\n",
    ")\n",
    "with tarfile.open(os.path.join(data_dir, \"brain_mri\", \"disc1.tar.gz\")) as tar:\n",
    "    tar.extractall(os.path.join(data_dir, 'brain_mri'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let's load a cross-sectional brain MRI into memory. Although organ tissue segmentation is inherently a three-dimensional task, weâ€™ll approximate it by segmenting 2-D cross-sectional MRI slices. This is less complex and compute-intensive than volumetric segmentation and performs reasonably well.\n",
    "\n",
    "Let's look at such a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf54737bd0>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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